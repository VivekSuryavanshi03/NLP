{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf34668f-6d85-4d25-8a6e-f75d1c87f074",
   "metadata": {},
   "outputs": [],
   "source": [
    " ## when we solve problem like sentiment analysis we use stemming \n",
    "## reviews ----->eating,eat,eaten  --> eat\n",
    "## having similar word we just put its root word and make it vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f1af068-f904-4c59-9500-6446626bf5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## to find the root word we use stemming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4783c7c4-51cf-480b-808b-f5f596d9593c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## due to excess in the tokens we have to minimize the tokens for better computations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a081b253-2e1c-4387-b998-53e036f6fb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"eating\", \"eats\", \"eaten\", \"writing\", \"writes\", \"running\", \"runner\", \"happily\", \"happiness\", \"playing\", \"plays\", \"played\", \"caring\", \"cared\", \"study\", \"studied\", \"studies\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64b3be2-1498-497e-9e6e-9af31fa6c1fd",
   "metadata": {},
   "source": [
    "porter stemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6897c2e0-bc21-4698-ab0d-921ec160715b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2829f22-3662-4f84-aa1b-dada285d012f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemming = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fefc24f9-9e78-4117-b8d3-28afe581d731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating----->eat\n",
      "eats----->eat\n",
      "eaten----->eaten\n",
      "writing----->write\n",
      "writes----->write\n",
      "running----->run\n",
      "runner----->runner\n",
      "happily----->happili\n",
      "happiness----->happi\n",
      "playing----->play\n",
      "plays----->play\n",
      "played----->play\n",
      "caring----->care\n",
      "cared----->care\n",
      "study----->studi\n",
      "studied----->studi\n",
      "studies----->studi\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"----->\"+stemming.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "93403c61-621c-41db-ace1-24aef8a5f051",
   "metadata": {},
   "outputs": [],
   "source": [
    "##some words meaning don't even make sence as study ---> studi (major disadvantage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e32ea73-d839-45fd-ae93-c02481e886e4",
   "metadata": {},
   "source": [
    "RegexpStemmer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "91df56a9-04c2-4e39-a89d-17bf274b1af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "984815e9-c006-4555-9c27-c5ddae1715d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_stemmer = RegexpStemmer('ing$|ed$', min=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e3bfe3ca-3544-489a-baea-79a691067db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem('eating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2776b7af-967f-44ea-af7f-897bc52ae1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating----->eat\n",
      "eats----->eats\n",
      "eaten----->eaten\n",
      "writing----->writ\n",
      "writes----->writes\n",
      "running----->runn\n",
      "runner----->runner\n",
      "happily----->happily\n",
      "happiness----->happiness\n",
      "playing----->play\n",
      "plays----->plays\n",
      "played----->play\n",
      "caring----->car\n",
      "cared----->car\n",
      "study----->study\n",
      "studied----->studi\n",
      "studies----->studies\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"----->\"+reg_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9503bb1a-efd4-4f9f-8077-ad866fa26f35",
   "metadata": {},
   "source": [
    "Snowball Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d5788c30-7f21-4cff-b5a8-b4c3e62af570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "181b30f6-5548-431a-a3c4-f34971c9afbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "SnowballStemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "65a25c46-580c-4351-8e01-a94de7ad982e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating----->eat\n",
      "eats----->eat\n",
      "eaten----->eaten\n",
      "writing----->write\n",
      "writes----->write\n",
      "running----->run\n",
      "runner----->runner\n",
      "happily----->happili\n",
      "happiness----->happi\n",
      "playing----->play\n",
      "plays----->play\n",
      "played----->play\n",
      "caring----->care\n",
      "cared----->care\n",
      "study----->studi\n",
      "studied----->studi\n",
      "studies----->studi\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"----->\"+SnowballStemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d7dbf4e8-904f-4001-9ef1-fe337b816962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fairly----->fairli\n",
      "sportingly----->sportingli\n"
     ]
    }
   ],
   "source": [
    "words1 = [\"fairly\",\"sportingly\"]\n",
    "for word in words1:\n",
    "    print(word+\"----->\"+stemming.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9e0538f2-fc58-47f3-a3c3-8a72e8eaef9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fairly -----> fairly\n",
      "sportingly -----> sportingly\n"
     ]
    }
   ],
   "source": [
    "reg_stemmer = RegexpStemmer('ing$|ed$')\n",
    "words1 = [\"fairly\", \"sportingly\"]\n",
    "for word in words1:\n",
    "    print(word + \" -----> \" + reg_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4fa8eaef-db84-4dda-a223-170b1a17f39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fairly----->fair\n",
      "sportingly----->sport\n"
     ]
    }
   ],
   "source": [
    "words1 = [\"fairly\",\"sportingly\"]\n",
    "for word in words1:\n",
    "    print(word+\"----->\"+SnowballStemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "020eecbd-6c1b-4ef6-8375-f177f5a65cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## to overcome there disadvantage we use Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efec1243-dc62-491d-a78a-681b775a45c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
